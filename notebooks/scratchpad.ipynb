{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nicho\\PyProjects\\CGAEL\\.conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ischar(token):\n",
    "    \"\"\"\n",
    "    Returns true only if provided 'token' is a string with a length of exactly 1.\n",
    "    \"\"\"\n",
    "    if not isinstance(token, str):\n",
    "        return False\n",
    "    return len(token) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_len_trim_to(data:list, length:int):\n",
    "    \"\"\"\n",
    "    If a list is longer than the provided length, it will be returned trimmed to the provided length.\n",
    "    If the list is shorter or equal in length, it will be returned unchanged.\n",
    "    \"\"\"\n",
    "    return data[:min(len(data), length)]\n",
    "\n",
    "def list_len_pad_to(data:list, length:int, pad):\n",
    "    \"\"\"\n",
    "    If a list is shorter than the provided length, it will be returned padded to the provided length by the pad token.\n",
    "    If the list is longer or equal in length, it will be returned unchanged.\n",
    "    \"\"\"\n",
    "    return data + [pad] * (length - len(data))\n",
    "\n",
    "def list_len_force_to(data:list, length:int, pad):\n",
    "    \"\"\"\n",
    "    If a list is longer than the provided length, it will be returned trimmed to the provided length.\n",
    "    If a list is shorter than the provided length, it will be returned padded to the provided length by the pad token.\n",
    "    If the list is equal in length, it will be returned unchanged.\n",
    "    \"\"\"\n",
    "    data = list_len_trim_to(data, length)\n",
    "    return list_len_pad_to(data, length, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageTokenSet():\n",
    "    def __init__(self, alphabet_tokens:list, pad_token:str):\n",
    "        # Ensure the pad_token is a single character.\n",
    "        if not ischar(pad_token):\n",
    "            raise ValueError(f\"'pad_token' must be a single character string. Got {pad_token}.\")\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "        # Get the alphabet_tokens as both a list and a set.\n",
    "        # The list will maintain the order of the tokens. (Later stored.)\n",
    "        # The set will allow for fast error checking. (Discarded after.)\n",
    "        if isinstance(alphabet_tokens, list):\n",
    "            alph_list = [x for x in alphabet_tokens] # deepcopy\n",
    "            alph_set = set(alphabet_tokens)\n",
    "        elif isinstance(alphabet_tokens, set):\n",
    "            alph_list = list(alphabet_tokens)\n",
    "            alph_set = alphabet_tokens\n",
    "        elif isinstance(alphabet_tokens, str):\n",
    "            alph_list = [*alphabet_tokens]\n",
    "            alph_set = set(alph_list)\n",
    "        else:\n",
    "            raise ValueError(f\"'alphabet_tokens' should be provided as either a list, set or string. Got type '{type(alphabet_tokens)}'.\")\n",
    "        \n",
    "        # Check for errors in alphabet.\n",
    "\n",
    "        # List and set size should be the same. If different, this indicates a duplicate token.\n",
    "        if len(alph_list) != len(alph_set):\n",
    "            raise ValueError(f\"{len(alph_list)-len(alph_set)} duplicate tokens detected in 'alphabet_tokens'.\")\n",
    "        # Pad token cannot be in alphabet.\n",
    "        if self.pad_token in alph_set:\n",
    "            raise ValueError(f\"'pad_token' {self.pad_token} cannot be in alphabet.\")\n",
    "        # Check that each token is a single character.\n",
    "        for x in alph_list:\n",
    "            if not ischar(x):\n",
    "                raise ValueError(f\"Each entry of 'alphabet_tokens' must be a single character. Got '{x}'.\")\n",
    "        \n",
    "        # Alphabet tokens validated. Store.\n",
    "        self.alphabet_tokens = alph_list\n",
    "\n",
    "        # Instantiate encoder & decoder.\n",
    "        self.encoder = layer.StringLookup(vocabulary=self.alphabet_tokens, oov_token=self.pad_token, output_mode=\"int\", invert=False)\n",
    "        self.decoder = layer.StringLookup(vocabulary=self.alphabet_tokens, oov_token=self.pad_token, output_mode=\"int\", invert=True)\n",
    "\n",
    "    @property\n",
    "    def token_count(self):\n",
    "        \"\"\"\n",
    "        The number of tokens in the language, including the pad token.\n",
    "        \"\"\"\n",
    "        return self.encoder.vocabulary_size()\n",
    "    \n",
    "    def encode(self, data:str, shape:tuple):\n",
    "        \"\"\"\n",
    "        Encodes a Python string into a TensorFlow tensor.\n",
    "        \"\"\"\n",
    "        # Different rank shapes need to be handled differently.\n",
    "        if len(shape) == 1:\n",
    "            # Just need to ensure that the resulting list is of the proper size.\n",
    "            data = list_len_force_to([*data], shape[0], self.pad_token)\n",
    "        elif len(shape) == 2:\n",
    "            # Split the input by whitespace.\n",
    "            data = [list(x) for x in data.split()]\n",
    "            # Ensure each word is the proper length.\n",
    "            data = [list_len_force_to(x, shape[1], self.pad_token) for x in data]\n",
    "            # Ensure there are the proper number of \"words\".\n",
    "            data = list_len_force_to(data, shape[0], [self.pad_token]*shape[1])\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported shape rank={len(shape)}.\")\n",
    "        # Send to encoder.\n",
    "        return self.encoder(data)\n",
    "    \n",
    "    def decode(self, data):\n",
    "        \"\"\"\n",
    "        Encodes a TensorFlow tensor, NumPy array or Python array to a Python string.\n",
    "        \"\"\"\n",
    "        # Send to decoder.\n",
    "        data = self.decoder(data).numpy()\n",
    "        # Different rank shapes need to be handled differently.\n",
    "        if len(data.shape) == 1:\n",
    "            data = b''.join(data).decode(\"utf-8\").rstrip(self.pad_token)\n",
    "        elif len(data.shape) == 2:\n",
    "            # Join letters.\n",
    "            data = [b''.join(x).decode(\"utf-8\").rstrip(self.pad_token) for x in data]\n",
    "            # Join words.\n",
    "            data = ' '.join([x for x in data if len(x) > 0])\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported shape rank={len(data.shape)}.\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 3 4 1 2]\n",
      " [4 2 3 4 0]\n",
      " [1 3 4 0 0]], shape=(3, 5), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[b'C', b'A', b'T', b'C', b'H'],\n",
       "       [b'T', b'H', b'A', b'T', b'-'],\n",
       "       [b'C', b'A', b'T', b'-', b'-']], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = LanguageTokenSet(\"CHAT\", '-')\n",
    "a = chat.encode(\"CATCH THAT CAT\", shape=(3,5))\n",
    "print(a)\n",
    "chat.decode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, 1, 2, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"CATCH THAT CAT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'H', 'A', 'T']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = [*\"CHAT\"]\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nicho\\PyProjects\\CGAEL\\.conda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = layer.StringLookup(vocabulary=alphabet, oov_token=pad, output_mode=\"int\", invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = layer.StringLookup(vocabulary=alphabet, oov_token=pad, output_mode=\"int\", invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nicho\\PyProjects\\CGAEL\\.conda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 2, 3, 4], dtype=int64)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.vocab_size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
